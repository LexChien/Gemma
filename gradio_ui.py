# gradio_ui.pyï¼ˆä¿®æ­£ç‰ˆï¼šç¢ºä¿æ­£ç¢º messages æ ¼å¼è¼¸å‡ºï¼‰

import gradio as gr
from model_loader import stream_generate

# æ”¹ç”¨ openai-style messages æ ¼å¼ï¼ˆGradio è¦æ±‚æ¯æ¢è¨Šæ¯ç‚º dictï¼‰
def chat_wrapper(message, history):
    if not message.strip():
        history.append({"role": "assistant", "content": "âš ï¸ è«‹è¼¸å…¥æœ‰æ•ˆçš„æå•"})
        yield history
        return

    history.append({"role": "user", "content": message})
    partial_response = ""
    for partial in stream_generate(message):
        partial_response += partial
        yield history + [{"role": "assistant", "content": partial_response}]

with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ’¬ Gemma-3 Streaming Chatbotï¼ˆæ–°ç‰ˆæ ¼å¼ï¼‰\næœ¬åœ°æ¨ç† - å³æ™‚è¼¸å‡ºï¼Œæ”¯æ´å¤šè¼ªå°è©±")

    chatbot = gr.Chatbot(label="Chatbot å°è©±è¦–çª—", type="messages")
    with gr.Row():
        msg = gr.Textbox(label="Prompt", placeholder="è«‹è¼¸å…¥æå•ï¼Œå¦‚ï¼šè«‹å¯«ä¸€é¦–è©©", scale=4)
        submit = gr.Button("æäº¤", variant="primary")

    clear = gr.Button("æ¸…é™¤å°è©±")
    state = gr.State([])

    submit.click(chat_wrapper, inputs=[msg, state], outputs=[chatbot], queue=True)
    clear.click(lambda: ([], ""), None, [chatbot, msg])

if __name__ == "__main__":
    demo.queue().launch(server_name="0.0.0.0", server_port=7860, share=False)
